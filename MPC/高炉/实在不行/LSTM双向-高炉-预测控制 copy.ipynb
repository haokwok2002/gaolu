{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 库文件\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skopt import gp_minimize\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "# 设置中文字体\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\", size=12)  # 替换为你的中文字体文件路径\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取Excel文件\n",
    "excel_path = f'C:\\\\Users\\\\haokw\\\\Documents\\\\GitHub\\\\gaolu\\\\MPC\\\\高炉\\\\0数据\\\\数据-时间戳.xlsx'\n",
    "df_sheet = pd.read_excel(excel_path, sheet_name='Sheet4') \n",
    "# print(df_sheet.info())\n",
    "print(df_sheet.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义输入输出参数\n",
    "input_term = ['富氧流量', '冷风流量', '热风温度', '设定喷煤量']\n",
    "output_term = ['铁口1温度插补', 'SI插补']\n",
    "time_term= '主参数时间戳'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 异常数据处理-处理前后对比\n",
    "# 创建数据框副本以避免修改原始数据\n",
    "df_sheet_process = df_sheet.copy()\n",
    "\n",
    "# 定义一个函数，用中位数替换异常值\n",
    "def replace_outliers_with_median(series):\n",
    "    # 计算列的中位数\n",
    "    median_value = series.median()\n",
    "    # 检测异常值\n",
    "    outliers = (series - median_value).abs() > 3.0 * series.std()  # 使用标准差作为阈值\n",
    "    # 使用中位数替换异常值\n",
    "    series[outliers] = median_value\n",
    "# 画出数据\n",
    "def plot_subplot(data_x,data_y_yuan,data_y,column):\n",
    "    plt.plot(data_x,data_y_yuan,'r-')\n",
    "    plt.plot(data_x,data_y,'m-')\n",
    "    # plt.xlabel(time_term, fontproperties=font)  # 使用中文标签\n",
    "    plt.ylabel(column, fontproperties=font)  # 使用中文标签\n",
    "    # 使用中文标签\n",
    "\n",
    "\n",
    "# 对指定列应用替代异常值的函数\n",
    "# replace_outliers_with_median(df_sheet_process[input_term[0]])\n",
    "# replace_outliers_with_median(df_sheet_process[input_term[1]])\n",
    "# replace_outliers_with_median(df_sheet_process[output_term[0]])\n",
    "# replace_outliers_with_median(df_sheet_process[output_term[1]])\n",
    "# replace_outliers_with_median(df_sheet_process[output_term[2]])\n",
    "# replace_outliers_with_median(df_sheet_process[output_term[3]])\n",
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# for idx, column in enumerate(input_term+output_term):\n",
    "    \n",
    "#     plt.subplot(len(input_term+output_term), 1, idx+1)\n",
    "#     plot_subplot(df_sheet_process[time_term].values,df_sheet[column].values,df_sheet_process[column].values,column)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出选取的数据\n",
    "def plot_subplot(data_x,data_y,column,index_predict,index_gaolu):\n",
    "    plt.plot(data_x,data_y,'-')\n",
    "    plt.plot(data_x[index_gaolu],data_y[index_gaolu],'m-')\n",
    "    plt.plot(data_x[index_predict],data_y[index_predict],'r-')\n",
    "    \n",
    "    # plt.xlabel(time_term, fontproperties=font)  # 使用中文标签\n",
    "    plt.ylabel(column, fontproperties=font)  # 使用中文标签\n",
    "\n",
    "# index = range(1300, 2500, 1)\n",
    "# index = range(4500, 6550, 1)\n",
    "\n",
    "# index = range(5000, 5610, 1)\n",
    "    \n",
    "# length = 3000\n",
    "# start1 = 200\n",
    "# start2 = 4000   829\n",
    "\n",
    "length1 = 500\n",
    "start1 = 0\n",
    "length2 = 827\n",
    "start2 = 0\n",
    "\n",
    "\n",
    "# length = 280\n",
    "# start1 = 3550\n",
    "# start2 = 4000\n",
    "index_predict   = range(start1, start1+length1+1, 1)\n",
    "index_gaolu     = range(start2, start2+length2+1, 1)\n",
    "# index = range(1, 7572, 1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for idx, column in enumerate(input_term+output_term):\n",
    "    plt.subplot(len(input_term+output_term), 1, idx+1)\n",
    "    plot_subplot(df_sheet_process[time_term].values,df_sheet_process[column].values,column,index_predict,index_gaolu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化、逆归一化\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 将数据存储为字典，每个键对应一列数据\n",
    "original_data_dict = {\n",
    "    input_term[0]:   df_sheet[input_term[0]].values,\n",
    "    input_term[1]:   df_sheet[input_term[1]].values,\n",
    "    input_term[2]:   df_sheet[input_term[2]].values,\n",
    "    input_term[3]:   df_sheet[input_term[3]].values,\n",
    "    output_term[0]:  df_sheet[output_term[0]].values,\n",
    "    output_term[1]:  df_sheet[output_term[1]].values\n",
    "}\n",
    "\n",
    "# 初始化缩放器\n",
    "scalers = {}\n",
    "\n",
    "# 进行拟合\n",
    "for column, data in original_data_dict.items():\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler.fit(data.reshape(-1, 1))  # 保证数据是列向量\n",
    "    scalers[column] = scaler\n",
    "\n",
    "# 进行归一化\n",
    "normalized_data_dict = {}\n",
    "for column, scaler in scalers.items():\n",
    "    normalized_data_dict[column] = scaler.transform(original_data_dict[column].reshape(-1, 1)).flatten()\n",
    "\n",
    "# 进行反归一化\n",
    "original_data_dict = {}\n",
    "for column, scaler in scalers.items():\n",
    "    original_data_dict[column] = scaler.inverse_transform(normalized_data_dict[column].reshape(-1, 1)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 标定归一化前后数据\n",
    "# data_point = np.array([1500]).reshape(-1, 1)\n",
    "# data1 = scalers[output_term[0]].transform(data_point).flatten()\n",
    "\n",
    "# data_point = np.array(data1).reshape(-1, 1)\n",
    "# data2 = scalers[output_term[0]].inverse_transform(data_point).flatten()\n",
    "\n",
    "# data_point = np.array([1510]).reshape(-1, 1)\n",
    "# data3 = scalers[output_term[0]].transform(data_point).flatten()\n",
    "\n",
    "# data_point = np.array(data3).reshape(-1, 1)\n",
    "# data4 = scalers[output_term[0]].inverse_transform(data_point).flatten()\n",
    "\n",
    "# print(data1)\n",
    "# print(data2)\n",
    "# print(data3)\n",
    "# print(data4)\n",
    "# print('每摄氏度的输出差：',(data3-data1)/(data4-data2))\n",
    "\n",
    "\n",
    "\n",
    "# data_point = np.array([0.5]).reshape(-1, 1)\n",
    "# data1 = scalers[output_term[1]].transform(data_point).flatten()\n",
    "\n",
    "# data_point = np.array(data1).reshape(-1, 1)\n",
    "# data2 = scalers[output_term[1]].inverse_transform(data_point).flatten()\n",
    "\n",
    "# data_point = np.array([0.6]).reshape(-1, 1)\n",
    "# data3 = scalers[output_term[1]].transform(data_point).flatten()\n",
    "\n",
    "# data_point = np.array(data3).reshape(-1, 1)\n",
    "# data4 = scalers[output_term[1]].inverse_transform(data_point).flatten()\n",
    "\n",
    "# print(data1)\n",
    "# print(data2)\n",
    "# print(data3)\n",
    "# print(data4)\n",
    "# print('每0.01浓度的输出差：',(data3-data1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 组合训练数据--拆分训练、测试集\n",
    "test_size = 0.10\n",
    "def make_data(u1_data,u2_data,u3_data,u4_data,y1_data,y2_data,test_size):\n",
    "    u1_data = u1_data\n",
    "    u2_data = u2_data\n",
    "    u3_data = u3_data\n",
    "    u4_data = u4_data\n",
    "\n",
    "    u1_data_1 = np.roll(u1_data, 1)\n",
    "    u2_data_1 = np.roll(u2_data, 1)\n",
    "    u3_data_1 = np.roll(u3_data, 1)\n",
    "    u4_data_1 = np.roll(u4_data, 1)\n",
    "\n",
    "    y1_data = y1_data\n",
    "    y2_data = y2_data\n",
    "\n",
    "    X = np.column_stack((   u1_data  [1:-1], u2_data  [1:-1], u3_data  [1:-1], u4_data  [1:-1],\n",
    "                            u1_data_1[1:-1], u2_data_1[1:-1], u3_data_1[1:-1], u4_data_1[1:-1],\n",
    "                            y1_data  [1:-1], y2_data  [1:-1])\n",
    "                        )\n",
    "    y = np.column_stack((y1_data[2:],y2_data[2:]))\n",
    "\n",
    "    # 使用 reshape 转换形状(457, 10) (457, 2)--->(457, 1, 10) (457, 1, 2)\n",
    "    X_reshaped = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "    y_reshaped = y.reshape((y.shape[0], 1, y.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_reshaped, \n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=42, \n",
    "                                                        shuffle=True)\n",
    "                                                        # shuffle=False)\n",
    "\n",
    "\n",
    "    # print(X_reshaped)\n",
    "    # print('gggggggg')\n",
    "    # print(X_train)\n",
    "    # print(X_test)\n",
    "    # print('gggggggg')\n",
    "    # print(y_reshaped)\n",
    "    # print('gggggggg')\n",
    "    # print(y_train)\n",
    "    # print(y_test)\n",
    "\n",
    "    y_test = y_test.reshape((y_test.shape[0],y_test.shape[2]))\n",
    "    y_train = y_train.reshape((y_train.shape[0],y_train.shape[2]))\n",
    "    print(X_train.shape,y_train.shape)\n",
    "    print(X_test.shape,y_test.shape)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test ,X_reshaped, y_reshaped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高炉模型列数据\n",
    "u1_data = normalized_data_dict[input_term[0]][index_gaolu]\n",
    "u2_data = normalized_data_dict[input_term[1]][index_gaolu]\n",
    "u3_data = normalized_data_dict[input_term[2]][index_gaolu]\n",
    "u4_data = normalized_data_dict[input_term[3]][index_gaolu]\n",
    "y1_data = normalized_data_dict[output_term[0]][index_gaolu]\n",
    "y2_data = normalized_data_dict[output_term[1]][index_gaolu]\n",
    "num_samples = y2_data.shape[0]\n",
    "\n",
    "\n",
    "# print('Oxygen_enrich_rate:', u1_data.shape)\n",
    "# print('Set_coal_amount:', u2_data.shape)\n",
    "# print('hot_wind_temp:', u3_data.shape)\n",
    "# print('hot_wind_presure:', u4_data.shape)\n",
    "# print('temp:', y1_data.shape)\n",
    "# print('Si_percent:', y2_data.shape)\n",
    "# print(num_samples)\n",
    "\n",
    "X_gaolu_train, X_gaolu_test,\\\n",
    "y_gaolu_train, y_gaolu_test ,X_reshaped, y_reshaped = make_data(u1_data,u2_data,u3_data,u4_data,y1_data,y2_data,\n",
    "                                        test_size=test_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测模型列数据\n",
    "u1_data = normalized_data_dict[input_term[0]][index_predict]\n",
    "u2_data = normalized_data_dict[input_term[1]][index_predict]\n",
    "u3_data = normalized_data_dict[input_term[2]][index_predict]\n",
    "u4_data = normalized_data_dict[input_term[3]][index_predict]\n",
    "y1_data = normalized_data_dict[output_term[0]][index_predict]\n",
    "y2_data = normalized_data_dict[output_term[1]][index_predict]\n",
    "num_samples = y2_data.shape[0]\n",
    "\n",
    "\n",
    "# print('Oxygen_enrich_rate:', u1_data.shape)\n",
    "# print('Set_coal_amount:', u2_data.shape)\n",
    "# print('hot_wind_temp:', u3_data.shape)\n",
    "# print('hot_wind_presure:', u4_data.shape)\n",
    "# print('temp:', y1_data.shape)\n",
    "# print('Si_percent:', y2_data.shape)\n",
    "# print(num_samples)\n",
    "\n",
    "X_predict_train, X_predict_test,\\\n",
    "y_predict_train, y_predict_test ,X_reshaped, y_reshaped = make_data(u1_data,u2_data,u3_data,u4_data,y1_data,y2_data,\n",
    "                                        test_size=test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(u1_data)\n",
    "# plt.plot(u2_data)\n",
    "# plt.plot(u3_data)\n",
    "# plt.plot(u4_data)\n",
    "# plt.plot(y1_data)\n",
    "# plt.plot(y2_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义LSTM模型\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MyRNNModel(torch.nn.Module):\n",
    "    def __init__(self,features_size,hidden_size,isbidirectional):\n",
    "        super(MyRNNModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=features_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=isbidirectional\n",
    "        )\n",
    "        if isbidirectional:\n",
    "            self.fc = nn.Linear(2 * hidden_size, 2)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        last_lstm_output = lstm_out[:, -1, :]\n",
    "        # print(last_lstm_output)\n",
    "        output = self.fc(last_lstm_output)\n",
    "        return output\n",
    "\n",
    "    def custom_loss(self, y_true, y_pred):\n",
    "        squared_diff = torch.pow(y_true - y_pred, 2)\n",
    "        sum_squared_diff = torch.sum(squared_diff)\n",
    "        mse = sum_squared_diff / len(y_true)\n",
    "        return mse\n",
    "\n",
    "    def my_fit(self, X_train, y_train, epochs=1, batch_size=32, lr=0.001):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        loss_list = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                x_batch = torch.tensor(X_train[i:i+batch_size], dtype=torch.float32)\n",
    "                y_batch = torch.tensor(y_train[i:i+batch_size], dtype=torch.float32)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = self(x_batch)\n",
    "                loss = self.custom_loss(y_batch, y_pred)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            average_epoch_loss = epoch_loss / (len(X_train) // batch_size + 1)\n",
    "            print(f'第 {epoch + 1}/{epochs} 轮, 误差: {average_epoch_loss:.4f}', end='\\r')\n",
    "            loss_list.append(average_epoch_loss)\n",
    "\n",
    "        return loss_list\n",
    "\n",
    "    def my_predict(self, X_test):\n",
    "        # 设置模型为评估模式，这会关闭 dropout 等层\n",
    "        self.eval()\n",
    "        # 将输入数据转换为张量，并设置 requires_grad=True\n",
    "        x_tensor = torch.tensor(X_test, dtype=torch.float32, requires_grad=True)\n",
    "        \n",
    "        # 获取模型的预测输出\n",
    "        y_pred = self(x_tensor)\n",
    "        # 保留预测值的梯度信息\n",
    "        y_pred.retain_grad()\n",
    "        # 返回预测结果和包含梯度信息的张量\n",
    "        return y_pred[:,0].detach().numpy(),y_pred[:,1].detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立高炉模型实例\n",
    "features_size = 10\n",
    "hidden_size = 16\n",
    "# 设置随机种子\n",
    "torch.manual_seed(0)\n",
    "model_gaolu = MyRNNModel(features_size = features_size, \n",
    "                        hidden_size = hidden_size,\n",
    "                        isbidirectional=False)\n",
    "epoch_sum_gaolu = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高炉模型训练\n",
    "epoch_once = 200\n",
    "epoch_sum_gaolu = epoch_sum_gaolu+epoch_once\n",
    "loss_history = model_gaolu.my_fit(X_gaolu_train, y_gaolu_train, epochs=epoch_once, batch_size=64,lr = 0.002)\n",
    "\n",
    "print('\\nepoch_sum:',epoch_sum_gaolu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高炉模型预测\n",
    "y_pred_0,y_pred_1  = model_gaolu.my_predict(X_gaolu_test)\n",
    "# 计算 RMSE、MRE\n",
    "y_test = y_gaolu_test\n",
    "# y_test = y_test[:70]\n",
    "# y_pred_0 = y_pred_0[:70]\n",
    "# y_pred_1 = y_pred_1[:70]\n",
    "\n",
    "\n",
    "\n",
    "y_test_0 = scalers[output_term[0]].inverse_transform((y_test[:, 0]).reshape(-1, 1)).flatten()\n",
    "y_test_1 = scalers[output_term[1]].inverse_transform((y_test[:, 1]).reshape(-1, 1)).flatten()\n",
    "y_pred_0_inverse_transform = scalers[output_term[0]].inverse_transform((y_pred_0).reshape(-1, 1)).flatten()\n",
    "y_pred_1_inverse_transform = scalers[output_term[1]].inverse_transform((y_pred_1).reshape(-1, 1)).flatten()\n",
    "\n",
    "rmse_0 = np.sqrt(mean_squared_error(y_test_0, y_pred_0_inverse_transform))\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_test_1, y_pred_1_inverse_transform))\n",
    "\n",
    "# 计算 \n",
    "mre_0 = np.mean(np.abs((y_test_0 - y_pred_0_inverse_transform) / y_test_0))\n",
    "mre_1 = np.mean(np.abs((y_test_1 - y_pred_1_inverse_transform) / y_test_1))\n",
    "\n",
    "# 打印结果\n",
    "# print(f\"输出0: RMSE: {rmse_0:.4f}, MRE: {mre_0:.4f}\")\n",
    "# print(f\"输出1: RMSE: {rmse_1:.4f}, MRE: {mre_1:.4f}\")\n",
    "print(f\"RMSE: {output_term[0]}: {rmse_0:.4f}, {output_term[1]}: {rmse_1:.4f}\")\n",
    "print(f\"MRE : {output_term[0]}: { mre_0:.4f}, {output_term[1]}: { mre_1:.4f}\")\n",
    "\n",
    "# plot_hit_rate_curve(y_test, y_pred_0, y_pred_1)\n",
    "\n",
    "\n",
    "output0 = y_test_0 - y_pred_0_inverse_transform\n",
    "output1 = y_test_1 - y_pred_1_inverse_transform\n",
    "\n",
    "# print(f\"误差分析0:平均值:{output0.std():.4f},方差:{output0.mean():.4f}\")\n",
    "# print(f\"误差分析1:平均值:{output1.std():.4f},方差:{output1.mean():.4f}\")\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(y_test_0,'r')\n",
    "plt.plot(y_pred_0_inverse_transform,'g')\n",
    "plt.ylabel(output_term[0], fontproperties=font)  # 使用中文标签\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(y_test_1,'r')\n",
    "plt.plot(y_pred_1_inverse_transform,'g')\n",
    "plt.ylabel(output_term[1], fontproperties=font)  # 使用中文标签\n",
    "#\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(output0,'r-')\n",
    "plt.ylabel(output_term[0]+'_err', fontproperties=font)  # 使用中文标签\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(output1,'g-')\n",
    "plt.ylabel(output_term[1]+'_err', fontproperties=font)  # 使用中文标签\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建预测模型实例\n",
    "features_size = 10\n",
    "hidden_size = 64\n",
    "# 设置随机种子\n",
    "torch.manual_seed(0)\n",
    "model = MyRNNModel(features_size = features_size, \n",
    "                    hidden_size = hidden_size,\n",
    "                    isbidirectional=True)\n",
    "epoch_sum = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测模型训练\n",
    "epoch_once = 200\n",
    "epoch_sum = epoch_sum+epoch_once\n",
    "loss_history = model.my_fit(X_predict_train, y_predict_train, epochs=epoch_once, batch_size=128,lr = 0.002)\n",
    "print('\\nepoch_sum:',epoch_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测模型预测\n",
    "y_pred_0,y_pred_1  = model.my_predict(X_predict_test)\n",
    "\n",
    "# 计算 RMSE、MRE\n",
    "y_test = y_predict_test\n",
    "# y_test = y_test[:-1]\n",
    "# y_pred_0 = y_pred_0[1:]\n",
    "# y_pred_1 = y_pred_1[1:]\n",
    "\n",
    "y_test_0 = scalers[output_term[0]].inverse_transform((y_test[:, 0]).reshape(-1, 1)).flatten()\n",
    "y_test_1 = scalers[output_term[1]].inverse_transform((y_test[:, 1]).reshape(-1, 1)).flatten()\n",
    "y_pred_0_inverse_transform = scalers[output_term[0]].inverse_transform((y_pred_0).reshape(-1, 1)).flatten()\n",
    "y_pred_1_inverse_transform = scalers[output_term[1]].inverse_transform((y_pred_1).reshape(-1, 1)).flatten()\n",
    "\n",
    "rmse_0 = np.sqrt(mean_squared_error(y_test_0, y_pred_0_inverse_transform))\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_test_1, y_pred_1_inverse_transform))\n",
    "\n",
    "# 计算 \n",
    "mre_0 = np.mean(np.abs((y_test_0 - y_pred_0_inverse_transform) / y_test_0))\n",
    "mre_1 = np.mean(np.abs((y_test_1 - y_pred_1_inverse_transform) / y_test_1))\n",
    "\n",
    "# 打印结果\n",
    "# print(f\"输出0: RMSE: {rmse_0:.4f}, MRE: {mre_0:.4f}\")\n",
    "# print(f\"输出1: RMSE: {rmse_1:.4f}, MRE: {mre_1:.4f}\")\n",
    "print(f\"RMSE: {output_term[0]}: {rmse_0:.4f}, {output_term[1]}: {rmse_1:.4f}\")\n",
    "print(f\"MRE : {output_term[0]}: { mre_0:.4f}, {output_term[1]}: { mre_1:.4f}\")\n",
    "\n",
    "# plot_hit_rate_curve(y_test, y_pred_0, y_pred_1)\n",
    "\n",
    "\n",
    "output0 = y_test_0 - y_pred_0_inverse_transform\n",
    "output1 = y_test_1 - y_pred_1_inverse_transform\n",
    "\n",
    "# print(f\"误差分析0:平均值:{output0.std():.4f},方差:{output0.mean():.4f}\")\n",
    "# print(f\"误差分析1:平均值:{output1.std():.4f},方差:{output1.mean():.4f}\")\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(y_test_0,'r')\n",
    "plt.plot(y_pred_0_inverse_transform,'g')\n",
    "plt.ylabel(output_term[0], fontproperties=font)  # 使用中文标签\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(y_test_1,'r')\n",
    "plt.plot(y_pred_1_inverse_transform,'g')\n",
    "plt.ylabel(output_term[1], fontproperties=font)  # 使用中文标签\n",
    "#\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(output0,'r-')\n",
    "plt.ylabel(output_term[0]+'_err', fontproperties=font)  # 使用中文标签\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(output1,'g-')\n",
    "plt.ylabel(output_term[1]+'_err', fontproperties=font)  # 使用中文标签\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_0,y_pred_1  = model.my_predict(X_predict_test)\n",
    "y_pred_0_predict = scalers[output_term[0]].inverse_transform((y_pred_0).reshape(-1, 1)).flatten()\n",
    "y_pred_1_predict = scalers[output_term[1]].inverse_transform((y_pred_1).reshape(-1, 1)).flatten()\n",
    "\n",
    "y_pred_0,y_pred_1  = model_gaolu.my_predict(X_predict_test)\n",
    "y_pred_0_gaolu = scalers[output_term[0]].inverse_transform((y_pred_0).reshape(-1, 1)).flatten()\n",
    "y_pred_1_gaolu = scalers[output_term[1]].inverse_transform((y_pred_1).reshape(-1, 1)).flatten()\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(y_pred_0_predict)\n",
    "plt.plot(y_pred_0_gaolu)\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(y_pred_1_predict)\n",
    "plt.plot(y_pred_1_gaolu)\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(y_pred_0_predict-y_pred_0_gaolu)\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(y_pred_1_predict-y_pred_1_gaolu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 保存模型参数到文件\n",
    "# torch.save(model.state_dict(), 'model_predict_params.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义预测\n",
    "model_predict = model\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def lstm_forward(input, initial_states, w_ih, w_hh, b_ih, b_hh):\n",
    "    h_0, c_0 = initial_states  # 初始状态  [b_size, hidden_size]\n",
    "    b_size, seq_len, input_size = input.shape\n",
    "    h_size = h_0.shape[-1]\n",
    "\n",
    "    h_prev, c_prev = h_0, c_0\n",
    "\n",
    "    # 使用 np.newaxis 在第一个维度上插入一个新的维度  # 使用 np.tile 在第一个维度上复制 b_size 次\n",
    "    w_ih_expanded = w_ih[np.newaxis, :, :]    \n",
    "    w_ih_batch = np.tile(w_ih_expanded, (b_size, 1, 1))\n",
    "    w_hh_expanded = w_hh[np.newaxis, :, :]    \n",
    "    w_hh_batch = np.tile(w_hh_expanded, (b_size, 1, 1))\n",
    "    # print(w_ih_batch.shape)\n",
    "\n",
    "    output_size = h_size\n",
    "    output = np.zeros((b_size, seq_len, output_size))  # 初始化一个输出序列\n",
    "    for t in range(seq_len):\n",
    "        x = input[:, t, :]  # 当前时刻的输入向量 [b,in_size]->[b,in_size,1]\n",
    "        w_times_x = np.matmul(w_ih_batch, x[:, :, np.newaxis]).squeeze(-1)   # bmm:含有批量大小的矩阵相乘\n",
    "        # [b, 4*hidden_size, 1]->[b, 4*hidden_size]\n",
    "        # 这一步就是计算了 Wii*xt|Wif*xt|Wig*xt|Wio*xt\n",
    "        w_times_h_prev = np.matmul(w_hh_batch, h_prev[:, :, np.newaxis]).squeeze(-1)\n",
    "        # [b, 4*hidden_size, hidden_size]*[b, hidden_size, 1]->[b,4*hidden_size, 1]->[b, 4*hidden_size]\n",
    "        # 这一步就是计算了 Whi*ht-1|Whf*ht-1|Whg*ht-1|Who*ht-1\n",
    "\n",
    "        # 分别计算输入门(i)、遗忘门(f)、cell门(g)、输出门(o)  维度均为 [b, h_size]\n",
    "        i_t = sigmoid(w_times_x[:, :h_size] + w_times_h_prev[:, :h_size] + b_ih[:h_size] + b_hh[:h_size])  # 取前四分之一\n",
    "        f_t = sigmoid(w_times_x[:, h_size:2*h_size] + w_times_h_prev[:, h_size:2*h_size]\n",
    "                            + b_ih[h_size:2*h_size] + b_hh[h_size:2*h_size])\n",
    "        g_t = np.tanh(w_times_x[:, 2*h_size:3*h_size] + w_times_h_prev[:, 2*h_size:3*h_size]\n",
    "                            + b_ih[2*h_size:3*h_size] + b_hh[2*h_size:3*h_size])\n",
    "        o_t = sigmoid(w_times_x[:, 3*h_size:] + w_times_h_prev[:, 3*h_size:]\n",
    "                            + b_ih[3*h_size:] + b_hh[3*h_size:])\n",
    "        c_prev = f_t * c_prev + i_t * g_t\n",
    "        h_prev = o_t * np.tanh(c_prev)\n",
    "\n",
    "        output[:, t, :] = h_prev\n",
    "\n",
    "    return output, (np.expand_dims(h_prev, axis=0), np.expand_dims(c_prev, axis=0))  # 官方是三维，在第0维扩一维\n",
    "\n",
    "\n",
    "\n",
    "def predict_my(data_input):\n",
    "\n",
    "    input = data_input  # 随机初始化一个输入序列\n",
    "    c_0 = np.zeros((data_input.shape[0], hidden_size))  # 初始值，不会参与训练\n",
    "    h_0 = np.zeros((data_input.shape[0], hidden_size))\n",
    "\n",
    "    output_forward, (h_n_me, c_n_me) = lstm_forward(input, (h_0, c_0), \n",
    "                                                model_predict.lstm.weight_ih_l0.detach().numpy(),\n",
    "                                                model_predict.lstm.weight_hh_l0.detach().numpy(), \n",
    "                                                model_predict.lstm.bias_ih_l0.detach().numpy(), \n",
    "                                                model_predict.lstm.bias_hh_l0.detach().numpy())\n",
    "\n",
    "    last_lstm_output_forward = output_forward[:, -1, :]\n",
    "\n",
    "    output_backward, (h_n_me, c_n_me) = lstm_forward(input, (h_0, c_0), \n",
    "                                                model_predict.lstm.weight_ih_l0_reverse.detach().numpy(),\n",
    "                                                model_predict.lstm.weight_hh_l0_reverse.detach().numpy(), \n",
    "                                                model_predict.lstm.bias_ih_l0_reverse.detach().numpy(), \n",
    "                                                model_predict.lstm.bias_hh_l0_reverse.detach().numpy())\n",
    "\n",
    "    last_lstm_output_backward = output_backward[:, -1, :]\n",
    "    # print(last_lstm_output_forward.shape)\n",
    "    # print(last_lstm_output_backward.shape)\n",
    "    # 最终输出\n",
    "    combined_hidden = np.concatenate((last_lstm_output_forward, last_lstm_output_backward), axis=1)\n",
    "    # print(combined_hidden.shape)\n",
    "\n",
    "\n",
    "    output = (np.dot(combined_hidden, np.transpose(model_predict.fc.weight.detach().numpy()))\n",
    "                + model_predict.fc.bias.detach().numpy()\n",
    ")\n",
    "    y_pred_0, y_pred_1= output[:,0],output[:,1]\n",
    "\n",
    "    # y_pred_0 = scalers[output_term[0]].inverse_transform(np.array(y_pred_0).reshape(-1, 1)).flatten()\n",
    "    # y_pred_1 = scalers[output_term[1]].inverse_transform(np.array(y_pred_1).reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return y_pred_0, y_pred_1\n",
    "\n",
    "\n",
    "y_pred_0, y_pred_1= predict_my(X_predict_test)\n",
    "\n",
    "\n",
    "# plot_hit_rate_curve(y_test, y_pred_0, y_pred_1)\n",
    "# plot_hit_rate_curve(y_test, y_pred_0.detach().numpy(), y_pred_1.detach().numpy())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成期望数据\n",
    "Times = 50\n",
    "\n",
    "def generate_y_aim_data(Times):\n",
    "\n",
    "    set_y1 = np.full(Times,1500)\n",
    "    set_y1[10:] = 1510\n",
    "    set_y1[20:] = 1500\n",
    "    # set_y1[130:151] = 1500\n",
    "    # set_y1[170:201] = 1500\n",
    "    # set_y1[85] = 1530  # 添加脉冲干扰\n",
    "\n",
    "    set_y2 = np.full(Times, 0.38)\n",
    "    set_y2[25:] = 0.43\n",
    "    set_y2[35:] = 0.38\n",
    "    # set_y2[65:] = 0.3  # 添加脉冲干扰\n",
    "    # set_y2[80:] = 0.5\n",
    "\n",
    "    # 限制设定值在 -1 到 1 之间\n",
    "    # set_y1 = np.clip(set_y1, -1, 1)\n",
    "    # set_y2 = np.clip(set_y2, -1, 1)\n",
    "\n",
    "\n",
    "    set_y1_trans = scalers[output_term[0]].transform(set_y1.reshape(-1,1)).flatten()\n",
    "    set_y2_trans = scalers[output_term[1]].transform(set_y2.reshape(-1,1)).flatten()\n",
    "\n",
    "    return set_y1, set_y2, set_y1_trans, set_y2_trans\n",
    "\n",
    "# # 调用示例\n",
    "# set_y1, set_y2, set_y1_trans, set_y2_trans= generate_y_aim_data(Times)\n",
    "# plt.plot(set_y1_trans)\n",
    "# plt.plot(set_y2_trans)\n",
    "# plt.title('y_sp')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成参考轨迹\n",
    "def get_yr(aim_value,current_value,alpha,P):\n",
    "    # 生成设定信号\n",
    "    setpoint_signal = np.full(10, aim_value)\n",
    "    # 初始化参数\n",
    "    alpha = alpha\n",
    "    y_r = np.zeros(P)\n",
    "    y_r[0] = current_value\n",
    "    # 模拟一阶模型\n",
    "    for k in range(1,P):\n",
    "        y_r[k] = alpha * y_r[k-1] + (1 - alpha) * aim_value\n",
    "\n",
    "    # # 绘制结果\n",
    "    # plt.plot(setpoint_signal, label='Setpoint Signal')\n",
    "    # plt.plot(y_r,'o-', label='Output Signal (Tracked)')\n",
    "    # plt.legend()\n",
    "    # plt.xlabel('Time')\n",
    "    # plt.ylabel('Amplitude')\n",
    "    # plt.title('Tracking Setpoint Signal with One-Order Model')\n",
    "    # plt.show()\n",
    "    return y_r\n",
    "# 测试\n",
    "y_r = get_yr(1,-0.5,0.667,5+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成控制时域的数据格式\n",
    "def generate_k_data(u1_data, u2_data, u3_data, u4_data, y1_data,y2_data, num_samples, P):\n",
    "    nearest_index = np.abs(y1_data - (-0.5)).argmin()\n",
    "    # 生成随机索引值\n",
    "    #从原有数据的randint时刻开始往下进行控制\n",
    "    randint = np.random.randint(1, num_samples - 2 - P - 1)\n",
    "    randint = nearest_index  # 如果你希望使用固定的值而不是随机生成\n",
    "    # randint = 250  # 如果你希望使用固定的值而不是随机生成\n",
    "    print(randint)\n",
    "    # 提取数据并构成 k_data\n",
    "    # 第一次得到下面五个变量，固定好格式构成k_data\n",
    "    u1   = u1_data[randint  :randint+2  ]\n",
    "    u2   = u2_data[randint  :randint+2  ]\n",
    "    u3   = u3_data[randint  :randint+2  ]\n",
    "    u4   = u4_data[randint  :randint+2  ]\n",
    "    u1_1 = u1_data[randint-1:randint+2-1]\n",
    "    u2_1 = u2_data[randint-1:randint+2-1]    \n",
    "    u3_1 = u3_data[randint-1:randint+2-1]\n",
    "    u4_1 = u4_data[randint-1:randint+2-1]\n",
    "\n",
    "    y1   = y1_data[randint  :randint+2  ]\n",
    "    y2   = y2_data[randint  :randint+2  ]\n",
    "    k_data = np.concatenate((u1, u2, u3, u4, u1_1, u2_1, u3_1, u4_1, y1, y2), axis=0)\n",
    "    # print(k_data.shape)\n",
    "\n",
    "    k_data = np.zeros_like(k_data)\n",
    "    return k_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义单时刻的MPC问题优化\n",
    "def my_MPC(k_data,params,M,P,y1_aim,y2_aim,isprint):\n",
    "    h1 = 0.8\n",
    "    h2 = 1.0\n",
    "    lamda1 = 0.001\n",
    "    lamda2 = 0.001\n",
    "    lamda3 = 0.001\n",
    "    lamda4 = 0.001\n",
    "    y1_percent = 1.0\n",
    "    y2_percent = 1.0\n",
    "    # lamda1 = 0.001\n",
    "    # y1_percent = 8.528\n",
    "    # y2_percent = 1.0\n",
    "\n",
    "    # 从固定格式k_data里面读取信息\n",
    "    u1   = k_data[0:2]\n",
    "    u2   = k_data[2:4]\n",
    "    u3   = k_data[4:6]\n",
    "    u4   = k_data[6:8]\n",
    "    u1_1 = k_data[8:10]\n",
    "    u2_1 = k_data[10:12]\n",
    "    u3_1 = k_data[12:14]\n",
    "    u4_1 = k_data[14:16]\n",
    "\n",
    "    y1   = k_data[16:18]\n",
    "    y2   = k_data[18:20]\n",
    "    # 获取猜测值[h U1 U2]\n",
    "    # h, U1, U2  =params[0], params[1:M+1],params[M+1:]\n",
    "    U1, U2, U3, U4  =params[0:M], params[M:2*M],params[2*M:3*M], params[3*M:4*M]\n",
    "\n",
    "    # 整理数据见   MPC推到.escel\n",
    "    u1   = np.concatenate((u1[:1],U1))\n",
    "    u2   = np.concatenate((u2[:1],U2))\n",
    "    u3   = np.concatenate((u3[:1],U3))\n",
    "    u4   = np.concatenate((u4[:1],U4))\n",
    "\n",
    "    u1_1 = np.concatenate((u1_1[:2],U1[:-1]))\n",
    "    u2_1 = np.concatenate((u2_1[:2],U2[:-1]))\n",
    "    u3_1 = np.concatenate((u3_1[:2],U3[:-1]))\n",
    "    u4_1 = np.concatenate((u4_1[:2],U4[:-1]))\n",
    "\n",
    "    y1   = np.concatenate((y1,np.zeros(P)))\n",
    "    y2   = np.concatenate((y2,np.zeros(P)))\n",
    "    y1_k = y1[1]\n",
    "    y2_k = y2[1]\n",
    "    # print(u1)\n",
    "    # print(u2)\n",
    "    # print(u1_1)\n",
    "    # print(u2_1)\n",
    "    # print(y1)\n",
    "    # print(y2)\n",
    "    # print(y1_k)    \n",
    "    # print(y2_k)\n",
    "\n",
    "    # 总共预测 P+1 次\n",
    "    # 对k时刻进行预测-----1次\n",
    "    for j in range(1):\n",
    "        x = np.column_stack((u1[j],u2[j],u3[j],u4[j],u1_1[j],u2_1[j],u3_1[j],u4_1[j],y1[j],y2[j]))\n",
    "        x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
    "        y1_m_k,y2_m_k = predict_my(x)\n",
    "        # y1[j+1] = y1_m_k.item()###############################是否替换不知道有没有影响？\n",
    "        # y2[j+1] = y2_m_k.item()###############################\n",
    "        # 在k时刻，我要先通过k-1时刻来预测出当前k时刻下的预测值。\n",
    "        # 实际上，这个时候我有k时刻的真实值。\n",
    "        # 但是这么做是为了能够获取我的预测值和真实值之间的误差，\n",
    "        # 然后基于这个误差，通过对控制器输入的调整来预测k+1时刻，\n",
    "        # 然后依次往下。因此，在k时刻，我系统的值是固定的，\n",
    "        # 也就是我的真实值，所以我要把它存储到我的整体的一个序列里面。\n",
    "        # 在取出当前k时刻真实值的过程中，我不能将之前预测的时候的那个\n",
    "        # 预测值覆盖掉真实值。后面新预测的数值要加上前面的那一个误差\n",
    "        E1_k = y1_k - y1_m_k\n",
    "        E2_k = y2_k - y2_m_k\n",
    "\n",
    "    # 对每个U对应的控制时刻进行预测-----M次\n",
    "    for j in range(1,M+1):  \n",
    "        x = np.column_stack((u1[j],u2[j],u3[j],u4[j],u1_1[j],u2_1[j],u3_1[j],u4_1[j],y1[j],y2[j]))\n",
    "        x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
    "        y1_k_j,y2_k_j = predict_my(x)\n",
    "        y1[j+1] = y1_k_j.item()#将预测值作为下一步的输出值\n",
    "        y2[j+1] = y2_k_j.item()\n",
    "\n",
    "    # 对控制时域外的部分进行预测-----P-M次\n",
    "    # 注意：这部分的信号是保持控制不变下进行\n",
    "    for j in range(M+1,P+1):\n",
    "        x = np.column_stack((u1[-1],u2[-1],u3[-1],u4[-1],u1[-1],u2[-1],u3[-1],u4[-1],y1[j],y2[j]))\n",
    "        x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
    "        y1_k_j,y2_k_j = predict_my(x)\n",
    "        y1[j+1] = y1_k_j.item()#将预测值作为下一步的输出值\n",
    "        y2[j+1] = y2_k_j.item()\n",
    "\n",
    "    k_data2 = np.concatenate((u1[1:3],u2[1:3],u3[1:3],u4[1:3],u1_1[1:3],u2_1[1:3],u3_1[1:3],u4_1[1:3],y1[1:3],y2[1:3]),axis=0)\n",
    "\n",
    "\n",
    "    \n",
    "    # y1_aim = scalers[output_term[0]].inverse_transform(np.array(y1_aim).reshape(-1, 1)).flatten()\n",
    "    # y1 = scalers[output_term[0]].inverse_transform(np.array(y1).reshape(-1, 1)).flatten()\n",
    "    # y1_k = scalers[output_term[0]].inverse_transform(np.array(y1_k).reshape(-1, 1)).flatten()\n",
    "    # y2_aim = scalers[output_term[1]].inverse_transform(np.array(y2_aim).reshape(-1, 1)).flatten()\n",
    "    # y2 = scalers[output_term[1]].inverse_transform(np.array(y2).reshape(-1, 1)).flatten()\n",
    "    # y2_k = scalers[output_term[1]].inverse_transform(np.array(y2_k).reshape(-1, 1)).flatten()\n",
    "    # E1_k = scalers[output_term[0]].inverse_transform(np.array(E1_k).reshape(-1, 1)).flatten()\n",
    "    # E2_k = scalers[output_term[1]].inverse_transform(np.array(E2_k).reshape(-1, 1)).flatten()\n",
    "    # u1 = scalers[input_term[0]].inverse_transform(np.array(u1).reshape(-1, 1)).flatten()\n",
    "    # u2 = scalers[input_term[1]].inverse_transform(np.array(u2).reshape(-1, 1)).flatten()\n",
    "    # u3 = scalers[input_term[2]].inverse_transform(np.array(u3).reshape(-1, 1)).flatten()\n",
    "    # u4 = scalers[input_term[3]].inverse_transform(np.array(u4).reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "    #和获取参考轨迹\n",
    "    # 一定要对照好做差的序列\n",
    "    y1_r_aim  = get_yr(y1_aim,y1_k,0.1,P+1)\n",
    "    y1_r = y1_r_aim[1:] \n",
    "\n",
    "\n",
    "    y2_r_aim  = get_yr(y2_aim,y2_k,0.1,P+1)\n",
    "    y2_r = y2_r_aim[1:] \n",
    "\n",
    "    y1_M_k = y1[2:]\n",
    "    y2_M_k = y2[2:]\n",
    "    if isprint==1:\n",
    "\n",
    "        print('y1_k',y1_k)  \n",
    "        print('y1_m_k',y1_m_k)    \n",
    "        print('y2_k',y2_k)  \n",
    "        print('y2_m_k',y2_m_k)    \n",
    "\n",
    "        print('temp:')\n",
    "        print('y1_aim',y1_aim)\n",
    "        print('y1_r_aim',y1_r_aim)\n",
    "        print('  ')\n",
    "        print('y1_r',y1_r)\n",
    "        print('y1_M_k+h1*E1_k',y1_M_k+h1*E1_k)\n",
    "        print('  ')\n",
    "        print('y1',y1)\n",
    "        print('h*E1_k',h1*E1_k)\n",
    "\n",
    "        print('Si_percent:')\n",
    "        print('y2_aim',y2_aim)\n",
    "        print('y2_r_aim',y2_r_aim)\n",
    "        print('y2_r',y2_r)\n",
    "        print('y2_M_k+h2*E2_k',y2_M_k+h2*E2_k)\n",
    "\n",
    "        print('y2',y2)\n",
    "        print('h*E2_k',h2*E2_k)\n",
    "\n",
    "        print('u:')\n",
    "        print(u1)\n",
    "        print(u2)\n",
    "        print(u3)\n",
    "        print(u4)\n",
    "\n",
    "\n",
    "\n",
    "    # 计算mse\n",
    "    # lamda1太大的话会导致y1_r和y1_M_k的误差加大*****************导致超调的原因\\与目标值之间存在间隙\n",
    "    \n",
    "    # if np.abs(y1_aim-y1_k)<0.0001 and np.abs(y2_aim-y2_k)<0.0001:\n",
    "    #     lamda1 = 1\n",
    "\n",
    "    y1_err = y1_percent*np.sum((y1_r-(y1_M_k+h1*E1_k))**2) \n",
    "    y2_err = y2_percent*np.sum((y2_r-(y2_M_k+h2*E2_k))**2) \n",
    "    u1_power = lamda1*np.sum(((np.diff(u1)**2)))\n",
    "    u2_power = lamda2*np.sum(((np.diff(u2)**2)))\n",
    "    u3_power = lamda3*np.sum(((np.diff(u3)**2)))\n",
    "    u4_power = lamda4*np.sum(((np.diff(u3)**2)))\n",
    "\n",
    "    mse = (0\n",
    "            # +loss_function(y1_r, y1_M_k+h*E1_k, weights)\n",
    "            # +loss_function(y2_r, y2_M_k+h*E2_k, weights)\n",
    "            # +(np.abs(y1_aim-y1_k)**2+np.abs(y2_aim-y2_k)**2)*P*2000\n",
    "            # +np.sum((y1_r-y1_M_k-h*E1_k)**2 + (y2_r-y2_M_k-h*E2_k)**2)\n",
    "            +y1_err\n",
    "            +y2_err\n",
    "            +u1_power\n",
    "            +u2_power\n",
    "            +u3_power\n",
    "            +u4_power\n",
    "\n",
    "            )\n",
    "    \n",
    "    # print('mse {:.7f}'.format(mse))\n",
    "    if isprint==1:\n",
    "        print('mse {:.7f}'.format(mse))\n",
    "        print('1111 {:.7f}'.format(y1_err))\n",
    "        print('2222 {:.7f}'.format(y2_err))\n",
    "        print('1111 {:.7f}'.format(u1_power))\n",
    "        print('2222 {:.7f}'.format(u2_power))\n",
    "        print('3333 {:.7f}'.format(u3_power))\n",
    "        print('4444 {:.7f}'.format(u4_power))\n",
    "\n",
    "\n",
    "\n",
    "    return mse , k_data2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对未来Times周期预测控制\n",
    "max_control = 1.0\n",
    "# 期望设定值\n",
    "set_y1, set_y2, set_y1_trans, set_y2_trans = generate_y_aim_data(Times)\n",
    "\n",
    "# MPC参数\n",
    "P = 3  # 预测时域长度\n",
    "M = 2  # 控制时域长度\n",
    "#生成控制时域的数据格式\n",
    "k_data = generate_k_data(u1_data, u2_data, u3_data, u4_data, \n",
    "                        y1_data, y2_data, num_samples, P)\n",
    "\n",
    "# MPC控制循环   迭代的只有：k_data\n",
    "all_pred_y1 = []\n",
    "all_pred_y2 = []\n",
    "all_pred_u1 = []\n",
    "all_pred_u2 = []\n",
    "all_pred_u3 = []\n",
    "all_pred_u4 = []\n",
    "# MPC控制循环\n",
    "for k in range(50):\n",
    "    print(f\"这是对第{k}时刻的最优U1、U2输入求解\")\n",
    "    # print('y1_aim  y2_aim',set_y1[k],set_y2[k])\n",
    "    # 定义优化目标函数\n",
    "    def objective_function(params, *k_data):\n",
    "        mse, k_data2 = my_MPC(k_data=k_data[0], params=params, \n",
    "                                M=M, P=P, \n",
    "                                y1_aim = set_y1_trans[k], y2_aim = set_y2_trans[k],\n",
    "                                isprint = 0) \n",
    "        return mse\n",
    "    \n",
    "    # 初始猜测值[h U1 U2]\n",
    "    params = np.concatenate([np.ones(M), np.ones(M),np.ones(M), np.ones(M)])\n",
    "    # 定义参数的上下限  \n",
    "    bounds = [(-max_control, max_control) for _ in range(4 * M)]\n",
    "    # 设置退出条件\n",
    "    exit_conditions = {'maxiter': 1000}  # 您可以根据需要调整容差\n",
    "\n",
    "    # 进行优化\n",
    "    result = minimize(objective_function, params, method='L-BFGS-B', \n",
    "                    bounds=bounds, args=k_data)#args传进来的是一个元组\n",
    "    \n",
    "    # # 查看退出条件\n",
    "    # if result.success:\n",
    "    #     print(\"优化成功收敛!\")\n",
    "    # else:\n",
    "    #     print(\"优化未成功收敛。\")\n",
    "    #     # 打印其他结果信息\n",
    "    # print(\"最优参数:\", result.x)\n",
    "    # print(\"最优函数值:\", result.fun)\n",
    "    # print(\"迭代次数:\", result.nit)\n",
    "    # print(\"Gradient:\", result.jac)\n",
    "    optimized_U1, optimized_U2, optimized_U3, optimized_U4 = result.x[0:M], result.x[M:2*M], result.x[2*M:3*M], result.x[3*M:4*M]\n",
    "\n",
    "\n",
    "    # 获取当前时刻下，在最优的U1、U2下的响应    \n",
    "    u1_k = optimized_U1[0]\n",
    "    u2_k = optimized_U2[0]\n",
    "    u3_k = optimized_U3[0]\n",
    "    u4_k = optimized_U4[0]\n",
    "    u1_k_1 = k_data[9]\n",
    "    u2_k_1 = k_data[11]\n",
    "    u3_k_1 = k_data[13]\n",
    "    u4_k_1 = k_data[15]\n",
    "    y1_k = k_data[17] \n",
    "    y2_k = k_data[19] \n",
    "    \n",
    "\n",
    "    \n",
    "    x = np.column_stack((u1_k,u2_k,u3_k,u4_k,u1_k_1,u2_k_1,u3_k_1,u4_k_1,y1_k,y2_k))\n",
    "    x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
    "    y1_pred0, y2_pred0 = model.my_predict(x)\n",
    "    print(y1_pred0, y2_pred0)\n",
    "    y1_pred, y2_pred = model_gaolu.my_predict(x)\n",
    "    print(y1_pred, y2_pred)\n",
    "    print(y1_pred-y1_pred0, y2_pred-y2_pred0)\n",
    "\n",
    "\n",
    "\n",
    "    # print(\"666666666666\")\n",
    "    \n",
    "    # 获取当前时刻下，在最优的U1、U2下的响应\n",
    "    params = np.concatenate((optimized_U1,optimized_U2,optimized_U3,optimized_U4),axis=0)\n",
    "    mse, k_data2 =my_MPC(k_data=k_data,params=params,\n",
    "                            M=M,P=P, \n",
    "                            y1_aim = set_y1_trans[k], y2_aim = set_y2_trans[k],\n",
    "                            isprint = 0) \n",
    "    \n",
    "    # print('y1_pred',scalers[output_term[0]].inverse_transform(np.array(y1_pred).reshape(-1, 1)).flatten())\n",
    "    # print('y2_pred',scalers[output_term[1]].inverse_transform(np.array(y2_pred).reshape(-1, 1)).flatten())\n",
    "    \n",
    "    all_pred_y1.append(y1_pred)\n",
    "    all_pred_y2.append(y2_pred)\n",
    "    all_pred_u1.append(u1_k)\n",
    "    all_pred_u2.append(u2_k)\n",
    "    all_pred_u3.append(u3_k)\n",
    "    all_pred_u4.append(u4_k)\n",
    "    k_data2[17] = y1_pred\n",
    "    k_data2[19] = y2_pred\n",
    "    k_data = k_data2\n",
    "    # 进入下一时刻，更新预测时域、控制时域，即k_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测控制结果可视化\n",
    "# 创建两个子图，分别绘制每个维度\n",
    "plt.figure(figsize=(8, 10))\n",
    "y1_pred_inverse_transform = scalers[output_term[0]].inverse_transform(np.array(all_pred_y1).reshape(-1, 1)).flatten()\n",
    "y2_pred_inverse_transform = scalers[output_term[1]].inverse_transform(np.array(all_pred_y2).reshape(-1, 1)).flatten()\n",
    "all_pred_u1_inverse_transform = scalers[input_term[0]].inverse_transform(np.array(all_pred_u1).reshape(-1, 1)).flatten()\n",
    "all_pred_u2_inverse_transform = scalers[input_term[1]].inverse_transform(np.array(all_pred_u2).reshape(-1, 1)).flatten()\n",
    "all_pred_u3_inverse_transform = scalers[input_term[2]].inverse_transform(np.array(all_pred_u3).reshape(-1, 1)).flatten()\n",
    "all_pred_u4_inverse_transform = scalers[input_term[3]].inverse_transform(np.array(all_pred_u4).reshape(-1, 1)).flatten()\n",
    "a1 = scalers[input_term[0]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "a2 = scalers[input_term[1]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "a3 = scalers[input_term[2]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "a4 = scalers[input_term[3]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "print(f'上线分别是：{a1}、{a2}、{a3}、{a4}')\n",
    "# print(all_pred_u1)\n",
    "# print(all_pred_u2)\n",
    "# print(all_pred_u3)\n",
    "# print(all_pred_u4)\n",
    "# 第一个维度的曲线\n",
    "plt.subplot(6, 1, 1)\n",
    "plt.plot(set_y1_trans, 'ro-', label='set_y1')\n",
    "plt.plot(all_pred_y1, 'bo-', label='y1')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,Times))\n",
    "plt.ylabel(output_term[0], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第二个维度的曲线\n",
    "plt.subplot(6, 1, 2)\n",
    "plt.plot(set_y2_trans, 'ro-', label='set_y2')\n",
    "plt.plot(all_pred_y2, 'bo-', label='y2')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,Times))\n",
    "plt.ylabel(output_term[1], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第一个维度的u1曲线\n",
    "plt.subplot(6, 1, 3)\n",
    "plt.plot(all_pred_u1, 'bo-', label='u1')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,Times))\n",
    "plt.ylim((-max_control,max_control))\n",
    "plt.ylabel(input_term[0], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第二个维度的u2曲线\n",
    "plt.subplot(6, 1, 4)\n",
    "plt.plot(all_pred_u2, 'bo-', label='u2')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,Times))\n",
    "plt.ylim((-max_control,max_control))\n",
    "plt.ylabel(input_term[1], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第三个维度的u3曲线\n",
    "plt.subplot(6, 1, 5)\n",
    "plt.plot(all_pred_u3, 'bo-', label='u3')  # 修改标签为 'u3'\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,Times))\n",
    "plt.ylim((-max_control,max_control))\n",
    "plt.ylabel(input_term[2], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第四个维度的u4曲线\n",
    "plt.subplot(6, 1, 6)\n",
    "plt.plot(all_pred_u4, 'bo-', label='u4')  # 修改标签为 'u4'\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,Times))\n",
    "plt.ylim((-max_control,max_control))\n",
    "plt.ylabel(input_term[3], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 调整子图布局\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测控制结果可视化\n",
    "# 创建两个子图，分别绘制每个维度\n",
    "plt.figure(figsize=(8, 10))\n",
    "y1_pred_inverse_transform = scalers[output_term[0]].inverse_transform(np.array(all_pred_y1).reshape(-1, 1)).flatten()\n",
    "y2_pred_inverse_transform = scalers[output_term[1]].inverse_transform(np.array(all_pred_y2).reshape(-1, 1)).flatten()\n",
    "all_pred_u1_inverse_transform = scalers[input_term[0]].inverse_transform(np.array(all_pred_u1).reshape(-1, 1)).flatten()\n",
    "all_pred_u2_inverse_transform = scalers[input_term[1]].inverse_transform(np.array(all_pred_u2).reshape(-1, 1)).flatten()\n",
    "all_pred_u3_inverse_transform = scalers[input_term[2]].inverse_transform(np.array(all_pred_u3).reshape(-1, 1)).flatten()\n",
    "all_pred_u4_inverse_transform = scalers[input_term[3]].inverse_transform(np.array(all_pred_u4).reshape(-1, 1)).flatten()\n",
    "a1 = scalers[input_term[0]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "a2 = scalers[input_term[1]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "a3 = scalers[input_term[2]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "a4 = scalers[input_term[3]].inverse_transform(np.array([1,-1]).reshape(-1, 1)).flatten()\n",
    "print(f'上线分别是：{a1}、{a2}、{a3}、{a4}')\n",
    "# print(all_pred_u1)\n",
    "# print(all_pred_u2)\n",
    "# print(all_pred_u3)\n",
    "# print(all_pred_u4)\n",
    "# 第一个维度的曲线\n",
    "plt.subplot(6, 1, 1)\n",
    "plt.plot(set_y1, 'ro-', label='set_y1')\n",
    "plt.plot(y1_pred_inverse_transform, 'bo-', label='y1')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,Times))\n",
    "plt.ylabel(output_term[0], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第二个维度的曲线\n",
    "plt.subplot(6, 1, 2)\n",
    "plt.plot(set_y2, 'ro-', label='set_y2')\n",
    "plt.plot(y2_pred_inverse_transform, 'bo-', label='y2')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,Times))\n",
    "plt.ylabel(output_term[1], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第一个维度的u1曲线\n",
    "plt.subplot(6, 1, 3)\n",
    "plt.plot(all_pred_u1, 'bo-', label='u1')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,Times))\n",
    "plt.ylim((-max_control,max_control))\n",
    "plt.ylabel(input_term[0], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第二个维度的u2曲线\n",
    "plt.subplot(6, 1, 4)\n",
    "plt.plot(all_pred_u2, 'bo-', label='u2')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,Times))\n",
    "plt.ylim((-max_control,max_control))\n",
    "plt.ylabel(input_term[1], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第三个维度的u3曲线\n",
    "plt.subplot(6, 1, 5)\n",
    "plt.plot(all_pred_u3, 'bo-', label='u3')  # 修改标签为 'u3'\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,Times))\n",
    "plt.ylim((-max_control,max_control))\n",
    "plt.ylabel(input_term[2], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 第四个维度的u4曲线\n",
    "plt.subplot(6, 1, 6)\n",
    "plt.plot(all_pred_u4, 'bo-', label='u4')  # 修改标签为 'u4'\n",
    "plt.axvline(x=0, color='gray', linestyle='--', linewidth=1.5)\n",
    "plt.xlim((0,Times))\n",
    "plt.ylim((-max_control,max_control))\n",
    "plt.ylabel(input_term[3], fontproperties=font)  # 使用中文标签\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7, color='gray')\n",
    "\n",
    "# 调整子图布局\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
